version: '3.5'

services:
  chatbot_engine:
    container_name: chatbot_engine
      # restart: always
    build:
      context: ../chatbot_util
      dockerfile: ../chatbot_util/Dockerfile
    image: chatbot_engine:dev
    environment:
      - PYTHONUNBUFFERED=1
      - TRANSFORMERS_CACHE=./cache/
    volumes:
      # - ../document_data/:/document_data/
      - ../chatbot_util/:/chatbot_util/
      - ~/.cache/huggingface/hub:/cache/huggingface/hub
    # command: python chatbot_util/gradio_ui.py
    # command: streamlit run streamlit_ui.py --server.port 7860
    # command: python chatbot_util/function_wrapper.py
    command: uvicorn chatbot_util.server:app --host 0.0.0.0 --port 7860
    ports:
      - ${engine_port}:${engine_port}
    networks:
      - net
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  document_db:
    container_name: document_db
    command:
    - --host
    - 0.0.0.0
    - --port
    - ${db_http_port}
    - --scheme
    - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.24.6
    ports:
    - ${db_http_port}
    - ${db_grpc_port}
    restart: on-failure:0
    volumes:
      - /${db_folder}:/var/lib/weaviate # <== set a volume here
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      LIMIT_RESOURCES: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'
      ENABLE_MODULES: ''
      CLUSTER_HOSTNAME: 'node1'
    networks:
      - net

volumes:
  document_data:
    driver: local
  backups:
    driver: local

networks:
  net:
    driver: bridge
